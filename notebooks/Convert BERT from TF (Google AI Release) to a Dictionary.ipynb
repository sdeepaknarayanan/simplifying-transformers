{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605bb85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 21:06:06.499338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "## I have TensorFlow 2.xx installed.... but BERT was saved using TF 1.xx ...\n",
    "import torch\n",
    "from transformers import BertConfig, BertForPreTraining, load_tf_weights_in_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc7307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tf_checkpoint_to_pytorch(tf_checkpoint_path, bert_config_file, pytorch_dump_path):\n",
    "    # Initialise PyTorch model\n",
    "    config = BertConfig.from_json_file(bert_config_file)\n",
    "    print(f\"Building PyTorch model from configuration: {config}\")\n",
    "    model = BertForPreTraining(config)\n",
    "\n",
    "    # Load weights from tf checkpoint\n",
    "    load_tf_weights_in_bert(model, config, tf_checkpoint_path)\n",
    "\n",
    "    # Save pytorch-model\n",
    "    print(f\"Save PyTorch model to {pytorch_dump_path}\")\n",
    "    torch.save(model.state_dict(), pytorch_dump_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd99e1",
   "metadata": {},
   "source": [
    "### To Obtain Raw TF Model\n",
    "\n",
    "Visit:https://github.com/google-research/bert#pre-trained-models and download the needed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50801a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building PyTorch model from configuration: BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 21:06:36.875023: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save PyTorch model to torch_dump_model\n"
     ]
    }
   ],
   "source": [
    "# Ignore local path -- change appropriately :)\n",
    "convert_tf_checkpoint_to_pytorch(\"BERT/tf_bert/uncased_L-12_H-768_A-12/bert_model.ckpt\",\n",
    "                                 \"BERT/tf_bert/uncased_L-12_H-768_A-12/bert_config.json\",\n",
    "                                 \"torch_dump_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
